{
	"cells": [{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Introduction\n",
				"OpenStreetMap (OSM) has a wealth of spatial data that is easily accessible via the Overpass API. This notebook explores how OSM data can be leveraged with other rich sources of spatial data. Since I'm a kiwi who's interested in public sector work, I'm using the spatial data available from StatsNZ. Also, I believe that the internet needs more analysis done with non-USA data!     \n",
				"\n",
				"The particular focus this notebook is how external sources of data can be combined with local government spatial data. In brief, the notebook covers:\n",
				"- Getting OSM data via Overpass\n",
				"- Calculating way polygon centroids as POI\n",
				"- Plotting POIs on Folium map\n",
				"- Loading administrative boundaries from Stats NZ\n",
				"- Aggregating data within an administrative boundary\n",
				"\n",
				"The motivation for this notebook is to obtain richer features for spatial flow modelling. I started out following the [excellent tutorial by Adam Dennett for modelling commuting patterns](https://rpubs.com/adam_dennett/376877). I [hacked out an equivalent in R for Wellington City commuters](https://github.com/shriv/wellington-commutes). But, by the end of the notebook, I realised that: (1) I needed much more exposure to the spatial data used by Stats NZ, and (2) the model was terrible; embarrassingly so - with 0% explained variance. Of course, the reason is that a garbage feature gives garbage predictions. In my case, the destination 'attractiveness' feature was beyond hopeless - the data actually had the opposite to expected dependence! I realised that I could add better features to the model if I only knew how to join the StatsNZ spatial data with other sources. This notebook works through an end to end generation of destination attractiveness features with OSM data: (1) number of commercial/ office buildings aggregated within the StatsNZ Statistical Area Unit (SA), and (2) land area covered by residential buildings within an SA. \n",
				"\n",
				"The key idea of these new features is to better represent where offices are located vs. residential areas. I want to be able to combine these to create a single feature that is correlated to workplace. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Import some packages\n",
				"import warnings\n",
				"import pandas as pd\n",
				"import matplotlib.pyplot as plt\n",
				"import seaborn as sns\n",
				"import folium\n",
				"import geopandas \n",
				"from shapely.geometry import Point, Polygon\n",
				"\n",
				"# User modules\n",
				"import utils.data_processing as dp\n",
				"\n",
				"# Some configs\n",
				"warnings.filterwarnings('ignore')\n",
				"pd.set_option('display.max_colwidth', -1)\n",
				"#%matplotlib inline"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Get OSM data\n",
				"OSM data is amazingly rich. It has two key components: (1) spatial objects,  and (2) a taxonomy for tagging the spatial objects. The root spatial primitive is a *node*. A collection of nodes makes up a *way*. Ways can be polygons or lines. Both nodes and ways [can be tagged](https://wiki.openstreetmap.org/wiki/Tags) with the extensive taxonomy specified by OSM. \n",
				"\n",
				"In [a previous analysis](https://github.com/shriv/fuel-stations), I focused on getting and analysing nodes from OSM. At the time, I believed that way data was not useful since it was a polygon and thus too complex to do anything with. I'm a changed woman now - way data is the *way forward*!\n",
				"\n",
				"Puns aside, the reason any polygon (way, spatial boundaries etc.) data is difficult to harness is because it actually requires understanding of spatial data manipulation - from theoretical aspects of projections and datums to reading in a diverse array spatial data formats. The problem gets more complicated when one wants to join  spatial datasets from different sources! Geo-munging is not trivial and sometimes the specificity of the datasets means that the entrypoint for a newbie is rather daunting! There are plenty of resources on the interwebs on geo-munging for sure but sadly none that met my needs. Hence, this little notebook. It brings together OSM data and spatial boundary datasets to derive interesting spatial features.\n",
				"\n",
				"There are 3 key steps to get data from OSM:\n",
				"- Generate the boundary box for the query\n",
				"- Write the query\n",
				"- Request data from OSM\n",
				"\n",
				"The final step is to transfrom the data into one that's suitable for the particular application. I've requested the data as JSON but I'm managing it with pandas / geopandas for analysis. "
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Define bounding box\n",
				"I've [written at some length about bounding boxes](http://htmlpreview.github.io/?https://github.com/shriv/fuel-stations/blob/master/html/Fuel%20Stations%20Analysis.html#Set-bounding-box) in my previous analysis with node data from OSM. So, here I'll just say that the bounding box defines a rectangular region that we're interested in with lattitude and longitude. The visual tool [here](http://boundingbox.klokantech.com/) can be used to get the vertices of the box. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Define bounding box (W, S, E, N) for the area of Wellington we're interested in\n",
				"general_bbox = [174.5813,-41.4552,175.0722,-41.1527]\n",
				"\n",
				"# Separate out the bounding box list into 4 vertices. \n",
				"south = general_bbox[1]\n",
				"west = general_bbox[0]\n",
				"north = general_bbox[3]\n",
				"east = general_bbox[2]\n",
				"\n",
				"# Set OSM bounding box\n",
				"osm_bbox = [south, west, north, east]"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Generate Overpass query\n",
				"Overpass is the API through which we access OSM data. I've cannibalised my Overpass query from various sources including [Geoff Boening's spatial analysis course notes](https://github.com/gboeing/urban-data-science/blob/master/20-Accessibility-Walkability/pandana-accessibility-demo-full.ipynb). The [Overpass Turbo site](http://overpass-turbo.eu/) can be used to test out the queries - you can inspect the data visually and through the specified output format. \n",
				"\n",
				"Since I'm interested in commerical buildings, I've generated a simple query for the Wellington City region that gets all *ways* that are tagged as commercial type buildings. The specific tags associated with these buildings are given in the code below. \n",
				"\n",
				"The query structure for my example is pretty simple. The following things need to be specified: \n",
				"- output format \n",
				"- timeout in seconds\n",
				"- the particular spatial entities we want to retrieve \n",
				"    - done by filtering on tags\n",
				"- the bounding box for the data"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [{
				"name": "stdout",
				"output_type": "stream",
				"text": [
					"[out:json][timeout:60];(way[\"building\" ~ \"commercial\"](-41.4552,174.5813,-41.1527,175.0722);way[\"building\" ~ \"office\"](-41.4552,174.5813,-41.1527,175.0722);way[\"building\" ~ \"retail\"](-41.4552,174.5813,-41.1527,175.0722);way[\"building\" ~ \"industrial\"](-41.4552,174.5813,-41.1527,175.0722););out body;>;out skel qt;\n"
				]
			}],
			"source": [
				"# What types of entitities do we want to get? \n",
				"tags = [\"commercial\", \"office\", \"retail\", \"industrial\"]\n",
				"objects = ['way'] # like way, node, relation\n",
				"entity = 'building'\n",
				"osm_objects = [entity] + tags + objects\n",
				"\n",
				"# Generate the query string\n",
				"compactOverpassQLstring = dp.generate_overpass_query(tags, objects, osm_bbox, entity)\n",
				"print(compactOverpassQLstring)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Get data\n",
				"The retreived JSON data can be transformed into a Pandas dataframe. At the moment, I have a minor problem with saving the way data as CSV - some of the node lists were getting truncated. This means that every re-run of the code will involve re-querying. Not great - but manageable at the moment since I'm not retreiving much data.  "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [{
				"data": {
					"text/html": [
						"<div>\n",
						"<style scoped>\n",
						"    .dataframe tbody tr th:only-of-type {\n",
						"        vertical-align: middle;\n",
						"    }\n",
						"\n",
						"    .dataframe tbody tr th {\n",
						"        vertical-align: top;\n",
						"    }\n",
						"\n",
						"    .dataframe thead th {\n",
						"        text-align: right;\n",
						"    }\n",
						"</style>\n",
						"<table border=\"1\" class=\"dataframe\">\n",
						"  <thead>\n",
						"    <tr style=\"text-align: right;\">\n",
						"      <th></th>\n",
						"      <th>LINZ2OSM:dataset</th>\n",
						"      <th>LINZ2OSM:layer</th>\n",
						"      <th>LINZ2OSM:source_version</th>\n",
						"      <th>addr:city</th>\n",
						"      <th>addr:country</th>\n",
						"      <th>addr:housename</th>\n",
						"      <th>addr:housenumber</th>\n",
						"      <th>addr:postcode</th>\n",
						"      <th>addr:street</th>\n",
						"      <th>alt_name</th>\n",
						"      <th>...</th>\n",
						"      <th>roof:levels</th>\n",
						"      <th>shop</th>\n",
						"      <th>smoking</th>\n",
						"      <th>source</th>\n",
						"      <th>substation</th>\n",
						"      <th>type</th>\n",
						"      <th>voltage</th>\n",
						"      <th>website</th>\n",
						"      <th>wikidata</th>\n",
						"      <th>year_of_construction</th>\n",
						"    </tr>\n",
						"  </thead>\n",
						"  <tbody>\n",
						"    <tr>\n",
						"      <th>0</th>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>Wellington</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>100</td>\n",
						"      <td>6011.0</td>\n",
						"      <td>Willis Street</td>\n",
						"      <td>NaN</td>\n",
						"      <td>...</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>way</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>Q10323215</td>\n",
						"      <td>NaN</td>\n",
						"    </tr>\n",
						"    <tr>\n",
						"      <th>1</th>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>...</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>way</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"    </tr>\n",
						"    <tr>\n",
						"      <th>2</th>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>Wellington</td>\n",
						"      <td>NZ</td>\n",
						"      <td>NaN</td>\n",
						"      <td>150</td>\n",
						"      <td>NaN</td>\n",
						"      <td>Willis Street</td>\n",
						"      <td>NaN</td>\n",
						"      <td>...</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>way</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"    </tr>\n",
						"    <tr>\n",
						"      <th>3</th>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>...</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>way</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"    </tr>\n",
						"    <tr>\n",
						"      <th>4</th>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>...</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>way</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"      <td>NaN</td>\n",
						"    </tr>\n",
						"  </tbody>\n",
						"</table>\n",
						"<p>5 rows × 47 columns</p>\n",
						"</div>"
					],
					"text/plain": [
						"  LINZ2OSM:dataset LINZ2OSM:layer LINZ2OSM:source_version   addr:city  \\\n",
						"0  NaN              NaN            NaN                     Wellington   \n",
						"1  NaN              NaN            NaN                     NaN          \n",
						"2  NaN              NaN            NaN                     Wellington   \n",
						"3  NaN              NaN            NaN                     NaN          \n",
						"4  NaN              NaN            NaN                     NaN          \n",
						"\n",
						"  addr:country addr:housename addr:housenumber  addr:postcode    addr:street  \\\n",
						"0  NaN          NaN            100              6011.0         Willis Street   \n",
						"1  NaN          NaN            NaN             NaN             NaN             \n",
						"2  NZ           NaN            150             NaN             Willis Street   \n",
						"3  NaN          NaN            NaN             NaN             NaN             \n",
						"4  NaN          NaN            NaN             NaN             NaN             \n",
						"\n",
						"  alt_name          ...          roof:levels shop smoking source substation  \\\n",
						"0  NaN              ...          NaN          NaN  NaN     NaN    NaN         \n",
						"1  NaN              ...          NaN          NaN  NaN     NaN    NaN         \n",
						"2  NaN              ...          NaN          NaN  NaN     NaN    NaN         \n",
						"3  NaN              ...          NaN          NaN  NaN     NaN    NaN         \n",
						"4  NaN              ...          NaN          NaN  NaN     NaN    NaN         \n",
						"\n",
						"  type  voltage website   wikidata  year_of_construction  \n",
						"0  way  NaN      NaN     Q10323215 NaN                    \n",
						"1  way  NaN      NaN     NaN       NaN                    \n",
						"2  way  NaN      NaN     NaN       NaN                    \n",
						"3  way  NaN      NaN     NaN       NaN                    \n",
						"4  way  NaN      NaN     NaN       NaN                    \n",
						"\n",
						"[5 rows x 47 columns]"
					]
				},
				"execution_count": 5,
				"metadata": {},
				"output_type": "execute_result"
			}],
			"source": [
				"# Get Data\n",
				"import importlib\n",
				"importlib.reload(dp)\n",
				"osmdf = dp.get_osm_data(compactOverpassQLstring, osm_bbox, osm_objects)\n",
				"osmdf.head()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Calculate polygon centroids"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [],
			"source": [
				"importlib.reload(dp)\n",
				"osmdf_clean = dp.extend_ways_to_node_view(osmdf)\n",
				"osmdf_centroids = osmdf_clean.groupby('way_id').agg({'lat': 'mean', 'lon': 'mean' }).reset_index()"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"env": {},
			"interrupt_mode": "signal",
			"language": "python",
			"metadata": {},
			"name": "python3"
		},
		"nikola": {
			"category": "",
			"date": "2019-07-30 15:07:37 UTC+12:00",
			"description": "",
			"link": "",
			"slug": "a-test-notebook",
			"tags": "",
			"title": "A test notebook",
			"type": "text"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
